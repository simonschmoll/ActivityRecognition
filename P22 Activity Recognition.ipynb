{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project 22: Activity Recognition\n",
    "## Authors: Alessandro Pomes, Simon Schmoll\n",
    "## Objectives: Classification of 7 activities which are tracked with a Single Chest-Mounted Accelerometer\n",
    "## What is done in the Notebook: The data is imported, processed and classified\n",
    "## As we followed a modular approach firstly the functions are defined which are later called for execution\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing the libraries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd #import panda for importing the dataset\n",
    "import numpy as np\n",
    "\n",
    "#Feature selection\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "#chi2 as we are dealing with a classifcation problem\n",
    "\n",
    "#imports for the classification\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing of the dataset\n",
    "## Method definition for reading one of the available datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Specifying engine = python because c engine can not handle 'sep'\n",
    "# @params: dataNum\n",
    "# @output: dataset (Dataframe)\n",
    "def read(data_num):\n",
    "    dataset = pd.read_csv('data/%d.csv' % (data_num), sep=',', header=None, engine='python', names=names_attributes)\n",
    "\n",
    "    # Comment in for printing out the array data and the size of the array\n",
    "    # print(array_data)\n",
    "    # print(np.size(array_data, 0))\n",
    "\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Checking for missing data\n",
    "## In the following lines, we check for missing values as these can falsify our data extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    " # definition of the function for deleting rows with '0' as a label\n",
    " # @input: Pandas Dataframe, value of lable to delete\n",
    " # @output: array of int without lable 0\n",
    "def zeroDet( dataset, value ):\n",
    "    num = []\n",
    "    num=(dataset.loc[dataset['lable'] == value].index.values)\n",
    "    dataClean=(dataset.drop(num))\n",
    "    dataClean = dataClean.as_matrix()\n",
    "    dataClean = dataClean.astype(np.int)\n",
    "    return dataClean\n",
    "\n",
    "#here we are trying to detect if there are some\n",
    "#missing data in all dataset.\n",
    "#To prove there aren't missing data,\n",
    "#output should generate empty arrays\n",
    "num = 1\n",
    "while(num < 16):\n",
    "    dataset = read_csv('data/%d.csv' % (num) , names=header)\n",
    "    boolData = dataset.isnull()\n",
    "    for name in header:\n",
    "        print(boolData.loc[boolData[name] == True])\n",
    "    num += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering\n",
    "## The goal is to extract features from the preprocessed numpy array\n",
    "## But before we have to do a preprocessing step\n",
    "## 1. Step is to sequence the data in windows with 52 instances \n",
    "## Sidenote: it is of high importance to not mix two labels into the same window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# For Feature Extraction we use a technique called window overlapping (Pierluigi Casale, Oriol Pujol, and Petia Radeva. Human activity recognition from accelerometer\n",
    "# data using a wearable device. Pattern Recognition and Image Analysis, pages 289â€“296, 2011). It has an overlap of 50% between the different\n",
    "# time series. As a time window 1 second is use --> corresponds to 52 samplings (52 Hz frequency)\n",
    "# Then we start with the sequencing\n",
    "# Slicing needs to be done as follows:\n",
    "# - it is not possible that 2 activities are grouped in one sequence (would falsify the outcome of the mean value)\n",
    "# - therefore only labels with the same value are grouped into one sequence\n",
    "# @params: array_data is list of array that contains the grouped data\n",
    "# @output: data_list which contains numpy arrays with the respective windows\n",
    "\n",
    "def grouping(array_data):\n",
    "    start = int(0)\n",
    "    end = int(52)\n",
    "    data_list = []\n",
    "    length = np.size(array_data, 0)\n",
    "    while start < length-52:\n",
    "        if(array_data[start][4] != array_data[end-1][4]):        # this control sequence is necessary to ensure that not two of the same\n",
    "            while(array_data[start][4] != array_data[end-1][4]): # labels are in one window\n",
    "                end = end -1\n",
    "            newArray = array_data[slice(start, end)]\n",
    "            start = end\n",
    "            end = end + 52\n",
    "        else:\n",
    "            newArray = array_data[slice(start, end)]\n",
    "            start = start + 26\n",
    "            end = end + 26\n",
    "        data_list.append(newArray)\n",
    "        if(end-52 > length - 1):\n",
    "            end = length-1\n",
    "\n",
    "    # Comment in to show the size and length of the data_list array\n",
    "    # print(np.size(data_list))\n",
    "    # print(len(data_list))\n",
    "    return data_list\n",
    "\n",
    "# This is an additional function which could be called to print a data list to a text file (e.g to examine it)\n",
    "# Comment in for printing the data to a text file\n",
    "# def sysout_to_text(dataList):\n",
    "#     file = open(\"tempFile\", \"w\")\n",
    "#     for item in dataList:\n",
    "#         file.write(\"%s\\n\" % item)\n",
    "#     file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Extraction\n",
    "# 2. Step we want to extract two feature types for each window (6 different features for each window - x-, y-, z- axis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Now we need to get the mean value and standard deviation of all windows\n",
    "#@Params: grouped data_List containing the window arrays\n",
    "#@Output: mean value of x, y, z, standard deviation of the coordinates, target array\n",
    "def extract_features(data_list):\n",
    "    total_average_values = []\n",
    "    total_label = []\n",
    "    for row in data_list:\n",
    "        acceleration = np.nanmean(row, 0)\n",
    "        standard_deviation = np.std(row, 0)\n",
    "        temp_features = [acceleration[1], acceleration[2], acceleration[3], standard_deviation[1], standard_deviation[2], standard_deviation[3]]\n",
    "        label_array = [row[0][4]]\n",
    "        total_average_values.append(temp_features)\n",
    "        total_label.append(label_array)\n",
    "    print(total_average_values)\n",
    "    print(total_label)\n",
    "    feature = np.vstack(total_average_values)\n",
    "    target = np.vstack(total_label)\n",
    "\n",
    "    # comment in to print out lists\n",
    "    # print(feature)\n",
    "    # print(target)\n",
    "    return feature, target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
